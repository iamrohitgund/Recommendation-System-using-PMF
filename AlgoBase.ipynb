{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12784d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, pairwise\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "class AlgoBase(object):\n",
    "    def __init__(self, learning_rate=.005, regularization=0.02, n_epochs=20,\n",
    "                 n_factors=100, min_rating=1, max_rating=5):\n",
    "        self.lr = learning_rate\n",
    "        self.reg = regularization\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_factors = n_factors\n",
    "        self.min_rating = min_rating\n",
    "        self.max_rating = max_rating\n",
    "        self.list_val_rmse = []\n",
    "        self.list_train_rmse = []\n",
    "        self.n_items = 0\n",
    "        self.n_users = 0\n",
    "        self.n_ratings = 0\n",
    "\n",
    "\n",
    "    def _initialization(self):\n",
    "        #to be implemented in child class \n",
    "        pass \n",
    "    \n",
    "\n",
    "    def _preprocess_data(self, X, train=True):\n",
    "        \"\"\"Maps users and items ids to indexes and returns a numpy array.\n",
    "        Args:\n",
    "            X (pandas DataFrame): dataset.\n",
    "            train (boolean): whether or not X is the training set or the\n",
    "                validation set.\n",
    "        Returns:\n",
    "            X (numpy array): mapped dataset.\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "\n",
    "        if train: # only create u_id, i_id dictionary when preprocessing training data\n",
    "            u_ids = X['u_id'].unique().tolist()\n",
    "            i_ids = X['i_id'].unique().tolist()\n",
    "            self.n_users = len(u_ids)\n",
    "            self.n_items = len(i_ids)\n",
    "            self.n_ratings = X.shape[0]\n",
    "            self.user_dict = dict(zip(u_ids, [i for i in range(self.n_users)]))\n",
    "            self.item_dict = dict(zip(i_ids, [i for i in range(self.n_items)]))\n",
    "\n",
    "        X['u_id'] = X['u_id'].map(self.user_dict)\n",
    "        X['i_id'] = X['i_id'].map(self.item_dict)\n",
    "\n",
    "        # Tag unknown users/items with -1 (validation data may have unseen user/items)\n",
    "        X.fillna(-1, inplace=True)\n",
    "\n",
    "        X['u_id'] = X['u_id'].astype(np.int32)\n",
    "        X['i_id'] = X['i_id'].astype(np.int32)\n",
    "\n",
    "        X = X[['u_id', 'i_id', 'rating']].values\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "    def _create_indicator_matrix(self):\n",
    "        '''create the indicator matrix from training data\n",
    "        , where I[user,item] indicate whether user rated item \n",
    "        '''\n",
    "        \n",
    "        self.I = np.zeros((self.n_users, self.n_items))\n",
    "        for u,i in self.train[:,:2]:\n",
    "            self.I[int(u), int(i)] = 1\n",
    "        self.n_user_rated = np.sum(self.I, axis = 1)\n",
    "        self.n_item_rated = np.sum(self.I, axis = 0)\n",
    "\n",
    "\n",
    "    def _prepare_user_inv_kernel_matrix(self, user_kernel_fn):\n",
    "        user_friends_df = pd.read_csv('user_friends.dat',encoding=\"utf-8\",sep=\"\\t\")\n",
    "        # select the entries only involving users in our training set. \n",
    "        user_friends_df = user_friends_df.loc[user_friends_df['userID'].isin(self.user_dict) \\\n",
    "                            & user_friends_df['friendID'].isin(self.user_dict)]\n",
    "        user_friends_df['userID'] = user_friends_df['userID'].map(self.user_dict)\n",
    "        user_friends_df['friendID'] = user_friends_df['friendID'].map(self.user_dict)\n",
    "        user_edge_list = user_friends_df.values.astype(np.int32)\n",
    "\n",
    "        self.Su = user_kernel_fn(user_edge_list, self.n_users)\n",
    "\n",
    "\n",
    "\n",
    "    def _prepare_item_inv_kernel_matrix(self, item_kernel_fn):\n",
    "        user_taggedartists_df= pd.read_csv('user_taggedartists.dat',encoding=\"utf-8\",sep=\"\\t\")\n",
    "        artist_tag_df = user_taggedartists_df.loc[user_taggedartists_df.artistID.isin(self.item_dict)][['artistID','tagID']]\n",
    "        #map tag id's to indices, map artist id's to indices\n",
    "        tag_ids = artist_tag_df.tagID.unique().tolist()\n",
    "        self.n_tags = len(tag_ids)\n",
    "        self.tag_dict = dict(zip(tag_ids, [i for i in range(self.n_tags)]))\n",
    "        artist_tag_df.artistID = artist_tag_df.artistID.map(self.item_dict)\n",
    "        artist_tag_df.tagID = artist_tag_df.tagID.map(self.tag_dict)\n",
    "        # create artist tag matrix \n",
    "        artist_tag_matrix = np.zeros((self.n_items, self.n_tags))\n",
    "        for a, t in artist_tag_df.values.astype(np.int32):\n",
    "            artist_tag_matrix[a-1 , t-1] = 1 \n",
    "        # create the inverse covariance matrix \n",
    "        self.Sv = item_kernel_fn(artist_tag_matrix)\n",
    "\n",
    "    def _on_epoch_begin(self, epoch_ix):\n",
    "        \"\"\"Displays epoch starting log and returns its starting time.\n",
    "        Args:\n",
    "            epoch_ix: integer, epoch index.\n",
    "        Returns:\n",
    "            start (float): starting time of the current epoch.\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        end = '  | ' if epoch_ix < 9 else ' | '\n",
    "        print('Epoch {}/{}'.format(epoch_ix + 1, self.n_epochs), end=end)\n",
    "\n",
    "        return start\n",
    "\n",
    "    def _on_epoch_end(self, start, train_rmse= None, val_rmse=None):\n",
    "        \"\"\"\n",
    "        Displays epoch ending log. If self.verbose compute and display\n",
    "        validation metrics (loss/rmse/mae).\n",
    "        # Arguments\n",
    "            start (float): starting time of the current epoch.\n",
    "            train_rmse: float, training rmse\n",
    "            val_rmse: float, validation rmse\n",
    "        \"\"\"\n",
    "        end = time.time()\n",
    "        val_rmse = self._compute_metrics(self.val)\n",
    "        train_rmse = self._compute_metrics(self.train)\n",
    "        print('train_rmse: {:.3f}'.format(train_rmse), end=' - ')\n",
    "        print('val_rmse: {:.3f}'.format(val_rmse), end=' - ')\n",
    "\n",
    "        print('took {:.1f} sec'.format(end - start))\n",
    "\n",
    "    def _sgd(self):\n",
    "        \"\"\"Performs SGD algorithm on training data, learns model parameters.\n",
    "        if not using early stopping, record all validation error and train error in a list \n",
    "        if using early stopping, dont modify list_val_rmse and list_train_rmse\n",
    "        stop after validation error is larger than the min validation error reached. \n",
    "        \"\"\"\n",
    "        self._initialization()\n",
    "        #reset the lists\n",
    "        self.list_val_rmse = [] #reset the lists \n",
    "        self.list_train_rmse = []\n",
    "        self.min_val = 999\n",
    "            \n",
    "            \n",
    "\n",
    "        # Run SGD\n",
    "        for epoch_ix in range(self.n_epochs):\n",
    "            start_time = self._on_epoch_begin(epoch_ix)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.train)\n",
    "\n",
    "            self._run_epoch()\n",
    "            val_rmse = self._compute_metrics(self.val)\n",
    "            train_rmse = self._compute_metrics(self.train)\n",
    "            \n",
    "            self.list_val_rmse.append(val_rmse)\n",
    "            self.list_train_rmse.append(train_rmse)\n",
    "            self.min_val = min(val_rmse, self.min_val)                \n",
    "\n",
    "            self._on_epoch_end(start_time, train_rmse, val_rmse)\n",
    "\n",
    "            # if early stopping and validation rmse didn't reduce enough , then break \n",
    "            if self.early_stopping and self.list_val_rmse[-1] - self.min_val > 0.01:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, train = None, val = None, early_stopping=False, shuffle=True, \\\n",
    "        user_side = False, user_kernel_fn = None, item_side = False, item_kernel_fn = None):\n",
    "        #Learns model parameters.always require validation data \n",
    "        self.early_stopping = early_stopping\n",
    "        self.shuffle = shuffle\n",
    "        self.user_side = user_side\n",
    "        self.item_side = item_side\n",
    "        print('Preprocessing data...')\n",
    "        self.train = self._preprocess_data(train)\n",
    "        self.val = self._preprocess_data(val, train=False)\n",
    "        self._create_indicator_matrix()\n",
    "        self.global_mean = np.mean(self.train[:, 2])\n",
    "        self.Su = np.diag(np.ones(self.n_users))\n",
    "        self.Sv = np.diag(np.ones(self.n_items))\n",
    "        if user_side: \n",
    "            print ('Preparing user side information')\n",
    "            #inverse of kernel matrix \n",
    "            self._prepare_user_inv_kernel_matrix(user_kernel_fn)\n",
    "        if item_side: \n",
    "            print ('Preparing item side information')\n",
    "            #inverse of kernel matrix \n",
    "            self._prepare_item_inv_kernel_matrix(item_kernel_fn)\n",
    "\n",
    "        self._sgd()\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        #Returns estimated ratings of several given user/item pairs.\n",
    "        predictions = []\n",
    "\n",
    "        for u_id, i_id in zip(X['u_id'], X['i_id']):\n",
    "            predictions.append(self.predict_pair(u_id, i_id))\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2e8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
